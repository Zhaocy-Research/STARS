{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "print(torch.cuda.is_available())\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from vis_model_high import lung_finetune_flex,ReconstructionModel,SegmentationModel,BaseModel\n",
    "from utils import *\n",
    "from predict import model_predict, sr_predict_lung_segmentation, sr_predict_lung_segmentation_spot\n",
    "from dataset import ViT_HER2ST, ViT_SKIN,HER2ST,LUNG,LUNG_HD\n",
    "from PIL import Image\n",
    "import glob\n",
    "from pytorch_lightning import LightningModule\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from scipy import stats\n",
    "import scanpy as sc\n",
    "import cv2\n",
    "import anndata\n",
    "import torch.nn.functional as F\n",
    "from skimage.segmentation import watershed\n",
    "os.environ[\"TORCH_CPP_LOG_LEVEL\"]=\"INFO\"\n",
    "os.environ[\"TORCH_DISTRIBUTED_DEBUG\"] = \"DETAIL\"\n",
    "# Check if CUDA is available\n",
    "print(torch.cuda.is_available())\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Dec  5 05:22:35 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100-SXM4-80GB          On  |   00000000:07:00.0 Off |                    0 |\n",
      "| N/A   33C    P0             65W /  400W |     425MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM4-80GB          On  |   00000000:0B:00.0 Off |                    0 |\n",
      "| N/A   31C    P0             60W /  400W |       3MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  NVIDIA A100-SXM4-80GB          On  |   00000000:48:00.0 Off |                    0 |\n",
      "| N/A   31C    P0             67W /  400W |    1427MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  NVIDIA A100-SXM4-80GB          On  |   00000000:4C:00.0 Off |                    0 |\n",
      "| N/A   33C    P0             62W /  400W |       3MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A     61905      C   ...conda3/envs/segmentation/bin/python        416MiB |\n",
      "|    2   N/A  N/A     61905      C   ...conda3/envs/segmentation/bin/python       1418MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # Reset/release all CUDA memory\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Additional step to reset all CUDA tensors (optional)\n",
    "    torch.cuda.ipc_collect()\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "from skimage.color import rgb2gray\n",
    "from stardist.models import StarDist2D\n",
    "from csbdeep.utils import normalize\n",
    "import tifffile as tiff\n",
    "# from scipy import ndimage\n",
    "# from skimage.measure import regionprops\n",
    "# from PIL import Image\n",
    "def stardist(image_array, labels_npz_path, stardist_model=\"2D_versatile_he\", block_size=4096*2, min_overlap=128, context=128, **kwargs):\n",
    "    '''\n",
    "    Segment an image with StarDist. Supports both the fluorescence and \n",
    "    H&E models. The identified object labels will be converted to a \n",
    "    sparse matrix and written to drive in ``.npz``.\n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    image_array : ``numpy array``\n",
    "        Image to be segmented.\n",
    "    labels_npz_path : ``filepath``\n",
    "        Path to write object labels output. Can be easily loaded via \n",
    "        ``scipy.sparse.load_npz()``.\n",
    "    stardist_model : ``str``, optional (default: ``\"2D_versatile_he\"``)\n",
    "        Use ``\"2D_versatile_he\"`` for segmenting H&E images or \n",
    "        ``\"2D_versatile_fluo\"`` for segmenting GEX-derived single-channel \n",
    "        images\n",
    "    block_size : ``int``, optional (default: 4096)\n",
    "        StarDist ``predict_instances_big()`` input. Length of square edge \n",
    "        of the image to process as a single tile. \n",
    "    min_overlap : ``int``, optional (default: 128)\n",
    "        StarDist ``predict_instances_big()`` input. Minimum overlap between \n",
    "        adjacent tiles, in each dimension.\n",
    "    context : ``int``, optional (default: 128)\n",
    "        StarDist ``predict_instances_big()`` input. Amount of image context \n",
    "        on all sides of a block, which is discarded.\n",
    "    kwargs\n",
    "        Any additional arguments to pass to StarDist. Practically most likely \n",
    "        to be ``prob_thresh`` for controlling the stringency of calling \n",
    "        objects.\n",
    "    '''\n",
    "    # Convert to grayscale if using the fluorescence model\n",
    "    if stardist_model == \"2D_versatile_fluo\":\n",
    "        image_array = rgb2gray(image_array)\n",
    "        \n",
    "    # Normalize the image\n",
    "    img = normalize(image_array, 7, 99.8, axis=(0, 1))\n",
    "    \n",
    "    # Use pretrained stardist model\n",
    "    model = StarDist2D.from_pretrained(stardist_model)\n",
    "    \n",
    "    # Specify axes\n",
    "    if stardist_model == \"2D_versatile_he\":\n",
    "        model_axes = \"YXC\"\n",
    "    elif stardist_model == \"2D_versatile_fluo\":\n",
    "        model_axes = \"YX\"\n",
    "    \n",
    "    # Run predict_instances_big() to perform automated tiling of the input\n",
    "    labels, _ = model.predict_instances_big(img, axes=model_axes, \n",
    "                                            block_size=block_size, \n",
    "                                            min_overlap=min_overlap, \n",
    "                                            context=context, \n",
    "                                            **kwargs\n",
    "                                           )\n",
    "    \n",
    "    # Store resulting labels as sparse matrix NPZ\n",
    "    labels_sparse = scipy.sparse.csr_matrix(labels)\n",
    "    scipy.sparse.save_npz(labels_npz_path, labels_sparse)\n",
    "    print(\"Found \" + str(len(np.unique(labels_sparse.data))) + \" objects\")\n",
    "    return labels\n",
    "def get_img(name):\n",
    "    if name in ['A1', 'A2', 'A3','A4']:\n",
    "        img_fold = os.path.join('/ix1/wchen/Zhaochongyue/spatial/Lung/ST/', name,\n",
    "                                'outs/spatial/full_image.tif')\n",
    "    elif name=='08_WT_F_S':\n",
    "        name='08_WT_F-S'\n",
    "        img_fold = os.path.join('/ix1/wchen/Shiyue/Projects/2023_06_Influ_Mouse_Lung_ST/RawData/Fastq/Alcorn_Visium_FFPE_Images/', name + '.TIF')\n",
    "    elif name=='09_WT_F_S':\n",
    "        name='09_WT_F-S'\n",
    "        img_fold = os.path.join('/ix1/wchen/Shiyue/Projects/2023_06_Influ_Mouse_Lung_ST/RawData/Fastq/Alcorn_Visium_FFPE_Images/', name + '.TIF')\n",
    "    else:\n",
    "        img_fold = '/ix1/wchen/liutianhao/data/public_lung_spatial/CRC_10X/HD/P1_CRC/Visium_HD_Human_Colon_Cancer_P1_tissue_image.btf'\n",
    "    print(os.path.exists(img_fold))\n",
    "    img_color = cv2.imread(img_fold, cv2.IMREAD_UNCHANGED).astype(np.float32)\n",
    "    img_color=img_color[:,:,0:3]\n",
    "    #print(img_color.shape,'shape')\n",
    "    # img_color = cv2.cvtColor(img_color, cv2.COLOR_BGR2RGB)  # Convert from BGR to RGB\n",
    "    #print(img_color.shape,'shape1')\n",
    "    return img_color\n",
    "names = ['P1_CRC']\n",
    "def read_bigtiff_in_chunks(file_path, chunk_size):\n",
    "    with tiff.TiffFile(file_path) as tif:\n",
    "        # Get image dimensions\n",
    "        image_shape = tif.series[0].shape\n",
    "        height, width = image_shape[:2]\n",
    "        channels = 1 if len(image_shape) == 2 else image_shape[2]\n",
    "\n",
    "        # Create an empty array to store the image\n",
    "        image = np.zeros((height, width, channels), dtype=np.float32)\n",
    "\n",
    "        # Read the image in chunks\n",
    "        for i in range(0, height, chunk_size):\n",
    "            for j in range(0, width, chunk_size):\n",
    "                chunk = tif.asarray(key=0)[i:i+chunk_size, j:j+chunk_size, :channels]\n",
    "                image[i:i+chunk_size, j:j+chunk_size, :channels] = chunk\n",
    "\n",
    "    return image\n",
    "def read_large_tiff(file_path):\n",
    "    # Read the image using tifffile\n",
    "    img_color = tiff.imread(file_path).astype(np.float32)\n",
    "\n",
    "    # If the image has more than three channels, select only the first three\n",
    "    if img_color.ndim == 3 and img_color.shape[2] > 3:\n",
    "        img_color = img_color[:, :, 0:3]\n",
    "\n",
    "    return img_color\n",
    "chunk_size = 1024  # Example chunk size\n",
    "btf_file_path='/ix1/wchen/liutianhao/data/public_lung_spatial/CRC_10X/HD/P1_CRC/Visium_HD_Human_Colon_Cancer_P1_tissue_image.btf'\n",
    "# Read the BigTIFF file in chunks\n",
    "image_rgb = read_large_tiff(btf_file_path)\n",
    "\n",
    "# print(names[0])\n",
    "# image_rgb = get_img(names[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array = np.array(image_rgb)\n",
    "np.save('/ix1/wchen/Zhaochongyue/spatial/crc_image_rgb.npy', image_array)\n",
    "labels_npz_path = '/ix1/wchen/Zhaochongyue/spatial/crc_labels.npz'\n",
    "labels=stardist(image_array, labels_npz_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the labels\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(labels, cmap='gray')\n",
    "plt.title('Segmented Labels')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does adata.obsm['spatial'] contain negative values? False\n"
     ]
    }
   ],
   "source": [
    "spatial_data = adata.obsm['spatial']\n",
    "has_negative_values = np.any(spatial_data < 0)\n",
    "\n",
    "print(f\"Does adata.obsm['spatial'] contain negative values? {has_negative_values}\")\n",
    "\n",
    "# Optionally, print the indices and values of the negative entries for further inspection\n",
    "if has_negative_values:\n",
    "    negative_indices = np.where(spatial_data < 0)\n",
    "    print(\"Indices of negative values in adata.obsm['spatial']:\", negative_indices)\n",
    "    print(\"Negative values in adata.obsm['spatial']:\", spatial_data[negative_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Barcode Patient   BC QCFilter       Level1       Level2\n",
      "0  AAACAAGCAACAGCACACTTTAGG-1   P2CRC  BC1   Remove  QC_Filtered  QC_Filtered\n",
      "1  AAACAAGCAACAGCTAACTTTAGG-1   P2CRC  BC1     Keep      B cells       Plasma\n",
      "2  AAACAAGCAACTGTTCACTTTAGG-1   P2CRC  BC1     Keep      T cells   CD4 T cell\n",
      "3  AAACAAGCAAGGCCTGACTTTAGG-1   P2CRC  BC1     Keep        Tumor    Tumor III\n",
      "4  AAACAAGCACATAGTGACTTTAGG-1   P2CRC  BC1     Keep        Tumor    Tumor III\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "h5_file_path = '/ix1/wchen/liutianhao/data/public_lung_spatial/CRC_10X/singlecell/HumanColonCancer_Flex_Multiplex_count_filtered_feature_bc_matrix.h5'\n",
    "adata_sc = sc.read_10x_h5(h5_file_path)\n",
    "meta_data = pd.read_csv('/ix1/wchen/Zhaochongyue/spatial/SingleCell_MetaData.csv')\n",
    "# Filter clusters with more than 25 cells\n",
    "kp_idents = meta_data['Level2'].value_counts()[meta_data['Level2'].value_counts() > 25].index\n",
    "filtered_meta_data = meta_data[meta_data['Level2'].isin(kp_idents)]\n",
    "# Ensure barcodes match in format between adata and meta_data\n",
    "adata_barcodes = adata_sc.obs_names\n",
    "meta_data_barcodes = filtered_meta_data['Barcode']\n",
    "# Check the intersection of barcodes\n",
    "common_barcodes = np.intersect1d(adata_barcodes, meta_data_barcodes)\n",
    "# Subset AnnData to only include the common barcodes\n",
    "adata_sc = adata_sc[common_barcodes]\n",
    "# Also filter the metadata to include only common barcodes\n",
    "filtered_meta_data = filtered_meta_data[filtered_meta_data['Barcode'].isin(common_barcodes)]\n",
    "# Set the Barcode as index to facilitate merging\n",
    "filtered_meta_data.set_index('Barcode', inplace=True)\n",
    "# Align the indices (barcodes) of the filtered metadata with the AnnData object\n",
    "adata_sc.obs = adata_sc.obs.join(filtered_meta_data, how='left')\n",
    "\n",
    "adata_sc.var_names_make_unique()\n",
    "\n",
    "names = ['P1_CRC']\n",
    "datasets = {}\n",
    "# all_centroids = []  # List to store all centroids\n",
    "# all_images = []  # List to store all images\n",
    "for name in names:\n",
    "    datasets[name] = get_cnt(name)\n",
    "    datasets[name].var_names_make_unique()\n",
    "# Find common genes between single-cell and other datasets\n",
    "common_genes = set(adata_sc.var_names)\n",
    "for data in datasets.values():\n",
    "    common_genes.intersection_update(set(data.var_names))\n",
    "adata_sc = adata_sc[:, list(common_genes)]\n",
    "for name in datasets:\n",
    "    datasets[name] = datasets[name][:, list(common_genes)]\n",
    "adata_sc = adata_sc[adata_sc.obs['QCFilter'] == \"Keep\"]\n",
    "adata_sc2=adata_sc\n",
    "\n",
    "sc.pp.normalize_total(adata_sc, target_sum=1e4)\n",
    "\n",
    "sc.pp.log1p(adata_sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "from scipy.sparse import isspmatrix\n",
    "sc.tl.rank_genes_groups(adata_sc, 'Level2', method='wilcoxon')\n",
    "# Define the number of top marker genes to extract\n",
    "marker_genes_data = sc.get.rank_genes_groups_df(adata_sc, group=None)\n",
    "logfc_threshold = 0.2\n",
    "min_diff_pct = 0.2\n",
    "p_val_adj_threshold = 0.05\n",
    "# Filter marker genes based on thresholds\n",
    "filtered_markers = marker_genes_data[\n",
    "    (marker_genes_data['logfoldchanges'] > logfc_threshold) & \n",
    "    (marker_genes_data['pvals_adj'] < p_val_adj_threshold)\n",
    "]\n",
    "# Calculate the percentage of cells expressing each gene in the group and reference populations\n",
    "group_counts = adata_sc.obs['Level2'].value_counts()\n",
    "gene_names = filtered_markers['names'].unique()\n",
    "# Create a DataFrame to store the fractions\n",
    "fractions = pd.DataFrame(index=gene_names, columns=group_counts.index)\n",
    "\n",
    "for group in group_counts.index:\n",
    "    group_idx = adata_sc.obs['Level2'] == group\n",
    "    group_data = adata_sc[group_idx, gene_names].X > 0\n",
    "    group_gene_counts = group_data.sum(axis=0).A1\n",
    "    fractions[group] = group_gene_counts / group_counts[group]\n",
    "\n",
    "# Calculate the rest of the population fractions\n",
    "rest_fractions = (adata_sc[:, gene_names].X > 0).sum(axis=0).A1 / adata_sc.shape[0]\n",
    "\n",
    "# Calculate the difference in fraction of expression\n",
    "filtered_markers['pct_diff'] = filtered_markers.apply(\n",
    "    lambda x: fractions.loc[x['names'], x['group']] - rest_fractions[gene_names.tolist().index(x['names'])], axis=1)\n",
    "\n",
    "# Filter based on percentage difference\n",
    "filtered_markers = filtered_markers[filtered_markers['pct_diff'] > min_diff_pct]\n",
    "\n",
    "# Select the top marker genes for each label\n",
    "# Select the top marker genes for each label\n",
    "top_marker_genes = defaultdict(list)\n",
    "for group in adata_sc.obs['Level2'].unique():\n",
    "    top_genes = filtered_markers[filtered_markers['group'] == group]['names'].tolist()\n",
    "    top_marker_genes[group].extend(top_genes)\n",
    "\n",
    "# Flatten the dictionary and count occurrences of each gene\n",
    "all_genes = [gene for genes in top_marker_genes.values() for gene in genes]\n",
    "gene_counts = Counter(all_genes)\n",
    "\n",
    "# Filter out non-unique marker genes\n",
    "unique_marker_genes = {group: [] for group in top_marker_genes.keys()}\n",
    "for group, genes in top_marker_genes.items():\n",
    "    unique_marker_genes[group] = [gene for gene in genes if gene_counts[gene] == 1]\n",
    "\n",
    "# Use all unique marker genes instead of selecting top 5\n",
    "selected_marker_genes = [gene for genes in unique_marker_genes.values() for gene in genes]\n",
    "\n",
    "marker_dict = {\n",
    "    'CD4 T cell': ['CD4'],  # List of markers for CD4+ T cells\n",
    "    'CD8 Cytotoxic T cell': ['CD8A', 'PRF1', 'GZMA', 'GZMK','CXCL9', 'CXCL10','CXCL11'],  # List of markers for CD8+ T cells\n",
    "    'Macrophage': ['C1QC', 'SELENOP', 'SPP1', 'STAB1','CD52','FBP1','IL1RN','FN1','LPL','CHI3L1','MMP7','CHIT1','CSF1R','MPEG1','MS4A6A','FGL2','SLC40A1','IGKC','CD209'],  # List of markers for Macrophages\n",
    "    'Mature B':['JCHAIN','MZB1']\n",
    "}\n",
    "\n",
    "# Initialize the dictionary to store marker genes\n",
    "small_marker_dict = defaultdict(list)\n",
    "\n",
    "# Directly assign the predefined markers to the small_marker_dict\n",
    "for cell_type, genes in marker_dict.items():\n",
    "    small_marker_dict[cell_type].extend(genes)\n",
    "\n",
    "# Extract the top 5 unique marker genes for each cell type\n",
    "# unique_marker_genes = {}\n",
    "for cell_type, genes in small_marker_dict.items():\n",
    "    unique_marker_genes[cell_type] = list(set(genes))  # Ensure uniqueness\n",
    "\n",
    "# Get the top 5 markers (if available)\n",
    "top_5_unique_marker_genes = {group: genes[:5] for group, genes in unique_marker_genes.items()}\n",
    "selected_marker_genes = [gene for genes in top_5_unique_marker_genes.values() for gene in genes if gene in common_genes]\n",
    "\n",
    "marker_file_data = []\n",
    "for group, genes in  top_5_unique_marker_genes.items():\n",
    "    for gene in genes:\n",
    "        marker_file_data.append({'gene': gene, 'label': group})\n",
    "marker_file_df = pd.DataFrame(marker_file_data)\n",
    "\n",
    "adata_sc_common = adata_sc[:, list(common_genes)].copy()\n",
    "sc.pp.highly_variable_genes(adata_sc_common, n_top_genes=1000)\n",
    "highly_variable_genes = adata_sc_common.var[adata_sc_common.var['highly_variable']].index.tolist()\n",
    "\n",
    "# Combine selected marker genes and highly variable genes\n",
    "\n",
    "final_gene_list = []\n",
    "for gene in selected_marker_genes:\n",
    "    if gene not in final_gene_list:\n",
    "        final_gene_list.append(gene)\n",
    "\n",
    "for gene in highly_variable_genes:\n",
    "    if gene not in final_gene_list:\n",
    "        final_gene_list.append(gene)\n",
    "# If the combined list exceeds 1000 genes, trim it to 1000\n",
    "if len(final_gene_list) > 1000:\n",
    "    final_gene_list = final_gene_list[:1000]\n",
    "with open('/ix1/wchen/Zhaochongyue/spatial/crc_hvg_list.pkl', 'wb') as f:\n",
    "    pickle.dump(final_gene_list, f)\n",
    "with open('/ix1/wchen/Zhaochongyue/spatial/crc_hvg_list.pkl', 'rb') as f:\n",
    "    final_gene_list = pickle.load(f)\n",
    "adata_sc = adata_sc2[:, final_gene_list]\n",
    "data = adata_sc.X\n",
    "if isspmatrix(data):  \n",
    "   data = data.toarray()\n",
    "data_min = data.min(axis=0)\n",
    "data_max = data.max(axis=0)\n",
    "\n",
    "adata_sc.X = (data - data_min) / (data_max - data_min+1e-12)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3075c9d43afab7d6b6c59d3d1f7d8f72e3bee7af38d099b34cdaad3f055ea015"
  },
  "kernelspec": {
   "display_name": "segmentation",
   "language": "python",
   "name": "segmentation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
